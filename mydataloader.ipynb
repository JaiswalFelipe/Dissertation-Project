{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mydataloader.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kbESbNscy7qP",
        "xKTKKSnuidnb",
        "KeoSfbDJCgYm",
        "TuyAP0UKuJBV",
        "6buxL7lciTgs"
      ],
      "mount_file_id": "1Ayc38Qo9yOJM72pp5-7GJHKBmwilKuTm",
      "authorship_tag": "ABX9TyOzHSLzv3LhJdiYbOvNo4ya",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaiswalFelipe/Dissertation-Project/blob/main/mydataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "kbESbNscy7qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagecodecs "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naq3HX4OBxOp",
        "outputId": "f52b4555-3b7f-4482-9ba7-0880eafbe1f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.7/dist-packages (2021.11.20)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import imageio\n",
        "import torch\n",
        "import torchvision\n",
        "import math\n",
        "import scipy.stats as stats\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils import data\n",
        "from skimage import transform\n",
        "from skimage import img_as_float\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from torchvision import transforms\n",
        "from skimage import transform\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "#from data_utils import create_or_load_statistics, create_distrib, normalize_images, data_augmentation\n",
        "\n",
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "EG8HkKPNQ1iV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "xKTKKSnuidnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "naq9Ch9EifW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data_utils"
      ],
      "metadata": {
        "id": "KeoSfbDJCgYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_image_mean(data):\n",
        "    _mean = np.mean(np.mean(np.mean(data, axis=0), axis=0), axis=0)\n",
        "    _std = np.std(np.std(np.std(data, axis=0, ddof=1), axis=0, ddof=1), axis=0, ddof=1)\n",
        "\n",
        "    return _mean, _std\n",
        "    \n",
        "\n",
        "def normalize_images(data, _mean, _std):\n",
        "    for i in range(len(_mean)):\n",
        "        data[:, :, i] = np.subtract(data[:, :, i], _mean[i])\n",
        "        data[:, :, i] = np.divide(data[:, :, i], _std[i])\n",
        "\n",
        "\n",
        "\n",
        "def data_augmentation(img, label=None):\n",
        "    rand_fliplr = np.random.random() > 0.50\n",
        "    rand_flipud = np.random.random() > 0.50\n",
        "    rand_rotate = np.random.random()\n",
        "\n",
        "    if rand_fliplr:\n",
        "        img = np.fliplr(img)\n",
        "        label = np.fliplr(label)\n",
        "    if rand_flipud:\n",
        "        img = np.flipud(img)\n",
        "        label = np.flipud(label)\n",
        "\n",
        "    if rand_rotate < 0.25:\n",
        "        img = transform.rotate(img, 270, order=1, preserve_range=True)\n",
        "        label = transform.rotate(label, 270, order=0, preserve_range=True)\n",
        "    elif rand_rotate < 0.50:\n",
        "        img = transform.rotate(img, 180, order=1, preserve_range=True)\n",
        "        label = transform.rotate(label, 180, order=0, preserve_range=True)\n",
        "    elif rand_rotate < 0.75:\n",
        "        img = transform.rotate(img, 90, order=1, preserve_range=True)\n",
        "        label = transform.rotate(label, 90, order=0, preserve_range=True)\n",
        "\n",
        "    img = img.astype(np.float32)\n",
        "    label = label.astype(np.int64)\n",
        "\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "pmVrwGdJucs1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils"
      ],
      "metadata": {
        "id": "TuyAP0UKuJBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WkZscUy3uM__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "xYrHMo31Cn4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training_data\n",
        "\n",
        "- should the vali data be reconsstructed? since we are only getting from training foler itself?\n"
      ],
      "metadata": {
        "id": "J_wDfE7fCuD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NGDataset(data.Dataset):\n",
        "  def __init__(self, dataset_input_path, images, output_path):\n",
        "\n",
        "    self.dataset_input_path = dataset_input_path\n",
        "    self.images = images\n",
        "    #self.img_dir = img_dir\n",
        "    #self.mask_dir = mask_dir\n",
        "    #self.images = os.listdir(img_dir)\n",
        "    #self.masks = os.listdir(mask_dir)\n",
        "\n",
        "    self.output_path = output_path\n",
        "\n",
        "\n",
        "    print(\"debug1\")\n",
        "    # data and label\n",
        "    self.data, self.labels = self.load_images()\n",
        "    print(\"debug2\")\n",
        "    #print(self.data.ndim, self.data.shape, self.data[0].shape, np.min(self.data), np.max(self.data),\n",
        "    #      self.labels.shape, np.bincount(self.labels.astype(int).flatten()))\n",
        "\n",
        "    if self.data.ndim == 4:  # if all images have the same shape\n",
        "       self.num_channels = self.data.shape[-1]  # get the number of channels\n",
        "    else:\n",
        "       self.num_channels = self.data[0].shape[-1]  # get the number of channels\n",
        "\n",
        "    self.num_classes = 2  # binary - two classes\n",
        "    # negative classes will be converted into 2 so they can be ignored in the loss\n",
        "    self.labels[np.where(self.labels < 0)] = 2\n",
        "    \n",
        "    print('num_channels and labels', self.num_channels, self.num_classes, np.bincount(self.labels.flatten()))\n",
        "\n",
        "    #self.distrib, self.gen_classes = self.make_dataset()\n",
        "\n",
        "    self.mean, self.std = compute_image_mean(self.data)\n",
        "\n",
        "  print(\"debug3\")\n",
        "\n",
        "  def load_images(self):\n",
        "        images = []\n",
        "        masks = []\n",
        "        for img in self.images:\n",
        "            temp_image = imageio.imread(os.path.join(self.dataset_input_path, img + '')).astype(np.float64)\n",
        "            temp_image[np.where(temp_image < -1.0e+38)] = 0 # remove extreme negative values (probably NO_DATA values)\n",
        "            \n",
        "            temp_mask = imageio.imread(os.path.join(self.dataset_input_path, img + '')).astype(int)\n",
        "            temp_mask[np.where(temp_mask < -1.0e+38)] = 0\n",
        "\n",
        "            images.append(temp_image)\n",
        "            masks.append(temp_mask)\n",
        "\n",
        "        return np.asarray(images), np.asarray(masks)\n",
        "\n",
        "  #def load_images(self):\n",
        "  #  images = []\n",
        "  #  masks = []\n",
        "  #  for img in os.listdir(self.img_dir):\n",
        "  #    image = imageio.imread(os.path.join(self.img_dir, img)).astype(np.float64)\n",
        "   #   image[np.where(image < -1.0e+38)] = 0 # remove extreme negative values (probably NO_DATA values)\n",
        "   #   \n",
        "   #   images.append(image)\n",
        "\n",
        "  #  for msk in os.listdir(self.mask_dir):\n",
        "  #   m = imageio.imread(os.path.join(masks, msk)).astype(int)\n",
        "  #    masks.append(m)\n",
        "\n",
        "  #  return np.asarray(images), np.asarray(masks) \n",
        "\n",
        "  print(\"debug4\")\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \n",
        "    #Reading items from list.\n",
        "    img = self.data[index]\n",
        "    label = self.labels[index]\n",
        "\n",
        "    # Normalization.\n",
        "    normalize_images(img, self.mean, self.std) # check data_utils.py\n",
        "    \n",
        "    # Data augmentation\n",
        "    img, label = data_augmentation(img, label)\n",
        "     \n",
        "    img = np.transpose(img, (2, 0, 1))\n",
        "\n",
        "    # Turning to tensors.\n",
        "    img = torch.from_numpy(img.copy())\n",
        "    label = torch.from_numpy(label.copy())\n",
        "\n",
        "    # Returning to iterator.\n",
        "    return img.float(), label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  print(\"debug5\")\n"
      ],
      "metadata": {
        "id": "Q7UNPeWWDVF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50074bd-3c55-40ea-eb74-81a6143e6f81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debug3\n",
            "debug4\n",
            "debug5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = '/content/drive/MyDrive/test2/img'\n",
        "#mask_path = '/content/drive/MyDrive/test2/msk'\n",
        "output_path = '/content/drive/MyDrive/Dissertation/outputs/'\n",
        "\n",
        "images = os.listdir(input_path)\n",
        "\n",
        "train_loader = NGDataset(input_path, images, output_path)\n"
      ],
      "metadata": {
        "id": "x-R2MNNomgIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16551e73-90b8-42f9-f390-fe550affbff2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debug1\n",
            "debug2\n",
            "num_channels and labels 23 2 [1847769  132706  631393 ...       0       0       1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HD4iqQlzGINc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training"
      ],
      "metadata": {
        "id": "6buxL7lciTgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import torch.optim as optim\n",
        "\n",
        "from albumentations.pytorch import ToTensorsV2\n",
        "from tqdm import tqdm \n",
        "\n",
        "#from utils import (\n",
        "#    load_checkpoint,\n",
        "#    save_checkpoint,\n",
        "#    get_loaders,\n",
        "#    check_accuracy\n",
        "#    save_predictions_as_imgs\n",
        "#)\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    # Setting network for training mode.\n",
        "    model.train()\n",
        "\n",
        "    # Average Meter for batch loss.\n",
        "    train_loss = list()\n",
        "\n",
        "    # Iterating over batches.\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, labels = data[0], data[1]\n",
        "\n",
        "        # if the current batch does not have samples from all classes\n",
        "        # print('out i', i, len(np.unique(labels.flatten())))\n",
        "        # if len(np.unique(labels.flatten())) < 10:\n",
        "        #     print('in i', i, len(np.unique(labels.flatten())))\n",
        "        #     continue\n",
        "\n",
        "        # Casting tensors to cuda.\n",
        "        inps = Variable(inps).cuda()\n",
        "        labs = Variable(labels).cuda()\n",
        "\n",
        "        # Clears the gradients of optimizer.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forwarding.\n",
        "        outs = model(inps)\n",
        "\n",
        "        # Computing loss.\n",
        "        loss = criterion(outs, labs)\n",
        "\n",
        "        if math.isnan(loss):\n",
        "            print('-------------------------NaN-----------------------------------------------')\n",
        "            print(inps.shape, labels.shape, outs.shape, np.bincount(labels.flatten()))\n",
        "            print(np.min(inps.cpu().data.numpy()), np.max(inps.cpu().data.numpy()),\n",
        "                  np.isnan(inps.cpu().data.numpy()).any())\n",
        "            print(np.min(labels.cpu().data.numpy()), np.max(labels.cpu().data.numpy()),\n",
        "                  np.isnan(labels.cpu().data.numpy()).any())\n",
        "            print(np.min(outs.cpu().data.numpy()), np.max(outs.cpu().data.numpy()),\n",
        "                  np.isnan(outs.cpu().data.numpy()).any())\n",
        "            print('-------------------------NaN-----------------------------------------------')\n",
        "            raise AssertionError\n",
        "\n",
        "        # Computing backpropagation.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Updating loss meter.\n",
        "        train_loss.append(loss.data.item())\n",
        "\n",
        "        # Printing.\n",
        "        if (i + 1) % DISPLAY_STEP == 0:\n",
        "            soft_outs = F.softmax(outs, dim=1)\n",
        "            # Obtaining predictions.\n",
        "            prds = soft_outs.cpu().data.numpy().argmax(axis=1).flatten()\n",
        "\n",
        "            labels = labels.cpu().data.numpy().flatten()\n",
        "\n",
        "            # filtering out pixels\n",
        "            coord = np.where(labels != train_loader.dataset.num_classes)\n",
        "            labels = labels[coord]\n",
        "            prds = prds[coord]\n",
        "\n",
        "            acc = accuracy_score(labels, prds)\n",
        "            conf_m = confusion_matrix(labels, prds, labels=[0, 1])\n",
        "            f1_s = f1_score(labels, prds, average='weighted')\n",
        "\n",
        "            _sum = 0.0\n",
        "            for k in range(len(conf_m)):\n",
        "                _sum += (conf_m[k][k] / float(np.sum(conf_m[k])) if np.sum(conf_m[k]) != 0 else 0)\n",
        "\n",
        "            print(\"Training -- Epoch \" + str(epoch) + \" -- Iter \" + str(i + 1) + \"/\" + str(len(train_loader)) +\n",
        "                  \" -- Time \" + str(datetime.datetime.now().time()) +\n",
        "                  \" -- Training Minibatch: Loss= \" + \"{:.6f}\".format(train_loss[-1]) +\n",
        "                  \" Overall Accuracy= \" + \"{:.4f}\".format(acc) +\n",
        "                  \" Normalized Accuracy= \" + \"{:.4f}\".format(_sum / float(train_loader.dataset.num_classes)) +\n",
        "                  \" F1 Score= \" + \"{:.4f}\".format(f1_s) +\n",
        "                  \" Confusion Matrix= \" + np.array_str(conf_m).replace(\"\\n\", \"\")\n",
        "                  )\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    return sum(train_loss) / len(train_loss), _sum / float(train_loader.dataset.num_classes)\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='main')\n",
        "    # general options\n",
        "    parser.add_argument('--operation', type=str, required=True, help='Operation [Options: Train | Test]')\n",
        "    parser.add_argument('--output_path', type=str, required=True,\n",
        "                        help='Path to to save outcomes (such as images and trained models) of the algorithm.')\n",
        "\n",
        "    # dataset options\n",
        "    parser.add_argument('--dataset_path', type=str, required=True, help='Dataset path.')\n",
        "    parser.add_argument('--training_images', type=str, nargs=\"+\", required=True, help='Training image names.')\n",
        "    parser.add_argument('--testing_images', type=str, nargs=\"+\", required=True, help='Testing image names.')\n",
        "    parser.add_argument('--crop_size', type=int, required=True, help='Crop size.')\n",
        "    parser.add_argument('--stride_crop', type=int, required=True, help='Stride size')\n",
        "\n",
        "    # model options\n",
        "    parser.add_argument('--model_name', type=str, required=True,\n",
        "                        choices=['deeplab', 'fcnwideresnet'], help='Model to evaluate')\n",
        "    parser.add_argument('--model_path', type=str, default=None, help='Model path.')\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.01, help='Learning rate')\n",
        "    parser.add_argument('--weight_decay', type=float, default=0.005, help='Weight decay')\n",
        "    parser.add_argument('--batch_size', type=int, default=128, help='Batch size')\n",
        "    parser.add_argument('--epoch_num', type=int, default=500, help='Number of epochs')\n",
        "\n",
        "    # handling imbalanced data\n",
        "    parser.add_argument('--loss_weight', type=float, nargs='+', default=[1.0, 1.0], help='Weight Loss.')\n",
        "    parser.add_argument('--weight_sampler', type=str2bool, default=False, help='Use weight sampler for loader?')\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "\n",
        "    # Making sure output directory is created.\n",
        "    pathlib.Path(args.output_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # writer for the tensorboard\n",
        "    writer = SummaryWriter(os.path.join(args.output_path, 'logs'))\n",
        "\n",
        "    if args.operation == 'Train':\n",
        "        print('---- training data ----')\n",
        "        train_set = DataLoader('Train', args.dataset_path, args.training_images, args.crop_size, args.stride_crop,\n",
        "                               args.output_path)\n",
        "        print('---- testing data ----')\n",
        "        test_set = DataLoader('Test', args.dataset_path, args.testing_images, args.crop_size, args.stride_crop,\n",
        "                              args.output_path)\n",
        "\n",
        "        if args.weight_sampler is False:\n",
        "            train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size,\n",
        "                                                       shuffle=True, num_workers=NUM_WORKERS, drop_last=False)\n",
        "        else:\n",
        "            class_loader_weights = 1. / np.bincount(train_set.gen_classes)\n",
        "            samples_weights = class_loader_weights[train_set.gen_classes]\n",
        "            sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weights, len(samples_weights),\n",
        "                                                                     replacement=True)\n",
        "            train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size,\n",
        "                                                       num_workers=NUM_WORKERS, drop_last=False, sampler=sampler)\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size,\n",
        "                                                  shuffle=False, num_workers=NUM_WORKERS, drop_last=False)\n",
        "\n",
        "        # Setting network architecture.\n",
        "        model = model_factory(args.model_name, train_set.num_channels, train_set.num_classes).cuda()\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(args.loss_weight),\n",
        "                                        ignore_index=train_set.num_classes).cuda()\n",
        "\n",
        "        # Setting optimizer.\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay,\n",
        "                               betas=(0.9, 0.99))\n",
        "        # optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay, momentum=0.9)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
        "\n",
        "        curr_epoch = 1\n",
        "        best_records = []\n",
        "        if args.model_path is not None:\n",
        "            print('Loading model ' + args.model_path)\n",
        "            best_records = np.load(os.path.join(args.output_path, 'best_records.npy'), allow_pickle=True)\n",
        "            model.load_state_dict(torch.load(args.model_path))\n",
        "            # optimizer.load_state_dict(torch.load(args.model_path.replace(\"model\", \"opt\")))\n",
        "            curr_epoch += int(os.path.basename(args.model_path)[:-4].split('_')[-1])\n",
        "            for i in range(curr_epoch):\n",
        "                scheduler.step()\n",
        "        model.cuda()\n",
        "\n",
        "        # Iterating over epochs.\n",
        "        print('---- training ----')\n",
        "        for epoch in range(curr_epoch, args.epoch_num + 1):\n",
        "            # Training function.\n",
        "            t_loss, t_nacc = train(train_loader, model, criterion, optimizer, epoch)\n",
        "            writer.add_scalar('Train/loss', t_loss, epoch)\n",
        "            writer.add_scalar('Train/acc', t_nacc, epoch)\n",
        "            if epoch % VAL_INTERVAL == 0:\n",
        "                # Computing test.\n",
        "                acc, nacc, f1_s, kappa, track_cm = test_full_map(test_loader, model, epoch, args.output_path)\n",
        "                writer.add_scalar('Test/acc', nacc, epoch)\n",
        "                save_best_models(model, args.output_path, best_records, epoch, kappa)\n",
        "                # patch_acc_loss=None, patch_occur=None, patch_chosen_values=None\n",
        "            scheduler.step()\n",
        "    elif args.operation == 'Test':\n",
        "        print('---- testing data ----')\n",
        "        test_set = DataLoader('Test', args.dataset_path, args.training_images, args.crop_size, args.stride_crop,\n",
        "                              args.output_path)\n",
        "        test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size,\n",
        "                                                  shuffle=False, num_workers=NUM_WORKERS, drop_last=False)\n",
        "\n",
        "        # Setting network architecture.\n",
        "        model = model_factory(args.model_name, test_set.num_channels, test_set.num_classes).cuda()\n",
        "\n",
        "        best_records = np.load(os.path.join(args.output_path, 'best_records.npy'), allow_pickle=True)\n",
        "        index = 0\n",
        "        for i in range(len(best_records)):\n",
        "            if best_records[index]['kappa'] < best_records[i]['kappa']:\n",
        "                index = i\n",
        "        epoch = int(best_records[index]['epoch'])\n",
        "        print(\"loading model_\" + str(epoch) + '.pth')\n",
        "        model.load_state_dict(torch.load(os.path.join(args.output_path, 'model_' + str(epoch) + '.pth')))\n",
        "        model.cuda()\n",
        "\n",
        "        test_full_map(test_loader, model, epoch, args.output_path)\n",
        "    else:\n",
        "        raise NotImplementedError(\"Process \" + args.operation + \"not found!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Z8SO1kqAiQVy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}