{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mydataloader.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kbESbNscy7qP",
        "xKTKKSnuidnb",
        "mthEhnvBTSnT",
        "WSIPgxRCTJ9X",
        "KeoSfbDJCgYm",
        "TuyAP0UKuJBV"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaiswalFelipe/Dissertation-Project/blob/main/mydataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "kbESbNscy7qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "tNj_EXeojF0-",
        "outputId": "c3d08760-23b2-47aa-e3fe-c771a688c62a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagecodecs "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naq3HX4OBxOp",
        "outputId": "52eea2e6-4ac5-4735-c3cb-5d1edc6ee234"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imagecodecs\n",
            "  Downloading imagecodecs-2021.11.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.0 MB 83.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.21.6)\n",
            "Installing collected packages: imagecodecs\n",
            "Successfully installed imagecodecs-2021.11.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import imageio\n",
        "import torch\n",
        "import torchvision\n",
        "import math\n",
        "import scipy.stats as stats\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils import data\n",
        "from skimage import transform\n",
        "from skimage import img_as_float\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from torchvision import transforms\n",
        "from skimage import transform\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "#from data_utils import create_or_load_statistics, create_distrib, normalize_images, data_augmentation\n",
        "\n",
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "EG8HkKPNQ1iV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "INUturaR6Jgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c194758-e595-4fb4-a01f-3bc69c1d95fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "xKTKKSnuidnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "mthEhnvBTSnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from torch import nn\n",
        "\n",
        "\n",
        "def initialize_weights(*models):\n",
        "    for model in models:\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                module.weight.data.fill_(1)\n",
        "                module.bias.data.zero_()\n"
      ],
      "metadata": {
        "id": "4BYCnIB5TVnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fcnwideresnet"
      ],
      "metadata": {
        "id": "WSIPgxRCTJ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "#from torch import nn\n",
        "#from torchvision import models\n",
        "#import torch.nn.functional as F\n",
        "\n",
        "#from networks.utils import initialize_weights\n",
        "\n",
        "\n",
        "class FCNWideResNet50(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes, pretrained=True, skip=True):\n",
        "        super(FCNWideResNet50, self).__init__()\n",
        "        self.skip = skip\n",
        "\n",
        "        # load pre-trained model\n",
        "        wideresnet = models.wide_resnet50_2(pretrained=pretrained, progress=False)\n",
        "\n",
        "        if input_channels == 3:\n",
        "            self.init = nn.Sequential(\n",
        "                wideresnet.conv1,\n",
        "                wideresnet.bn1,\n",
        "                wideresnet.relu,\n",
        "                wideresnet.maxpool\n",
        "            )\n",
        "        else:\n",
        "            self.init = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                wideresnet.bn1,\n",
        "                wideresnet.relu,\n",
        "                wideresnet.maxpool\n",
        "            )\n",
        "        self.layer1 = wideresnet.layer1  # output feat = 256\n",
        "        self.layer2 = wideresnet.layer2  # output feat = 512\n",
        "        self.layer3 = wideresnet.layer3  # output feat = 1024\n",
        "        self.layer4 = wideresnet.layer4  # output feat = 2048\n",
        "\n",
        "        if self.skip:\n",
        "            self.classifier1 = nn.Sequential(\n",
        "                nn.Conv2d(2048 + 512, 128, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout2d(0.5),\n",
        "            )\n",
        "        else:\n",
        "            self.classifier1 = nn.Sequential(\n",
        "                nn.Conv2d(2048, 128, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout2d(0.5),\n",
        "            )\n",
        "        self.final = nn.Conv2d(128, num_classes, kernel_size=3, padding=1)\n",
        "\n",
        "        if not pretrained:\n",
        "            initialize_weights(self)\n",
        "        else:\n",
        "            initialize_weights(self.classifier1)\n",
        "            initialize_weights(self.final)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fv_init = self.init(x)\n",
        "        fv1 = self.layer1(fv_init)\n",
        "        fv2 = self.layer2(fv1)\n",
        "        fv3 = self.layer3(fv2)\n",
        "        fv4 = self.layer4(fv3)\n",
        "\n",
        "        if self.skip:\n",
        "            # Forward on FCN with Skip Connections.\n",
        "            fv_final = torch.cat([F.interpolate(fv2, x.size()[2:], mode='bilinear', align_corners=False),\n",
        "                                  F.interpolate(fv4, x.size()[2:], mode='bilinear', align_corners=False)], 1)\n",
        "        else:\n",
        "            # Forward on FCN without Skip Connections.\n",
        "            fv_final = F.interpolate(fv4, x.size()[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        classif1 = self.classifier1(fv_final)\n",
        "        output = self.final(classif1)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "naq9Ch9EifW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data_utils"
      ],
      "metadata": {
        "id": "KeoSfbDJCgYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_image_mean(data):\n",
        "    _mean = np.mean(np.mean(np.mean(data, axis=0), axis=0), axis=0)\n",
        "    _std = np.std(np.std(np.std(data, axis=0, ddof=1), axis=0, ddof=1), axis=0, ddof=1)\n",
        "\n",
        "    return _mean, _std\n",
        "    \n",
        "\n",
        "def normalize_images(data, _mean, _std):\n",
        "    for i in range(len(_mean)):\n",
        "        data[:, :, i] = np.subtract(data[:, :, i], _mean[i])\n",
        "        data[:, :, i] = np.divide(data[:, :, i], _std[i])\n",
        "\n",
        "\n",
        "\n",
        "def data_augmentation(img, label=None):\n",
        "    rand_fliplr = np.random.random() > 0.50\n",
        "    rand_flipud = np.random.random() > 0.50\n",
        "    rand_rotate = np.random.random()\n",
        "\n",
        "    if rand_fliplr:\n",
        "        img = np.fliplr(img)\n",
        "        label = np.fliplr(label)\n",
        "    if rand_flipud:\n",
        "        img = np.flipud(img)\n",
        "        label = np.flipud(label)\n",
        "\n",
        "    if rand_rotate < 0.25:\n",
        "        img = transform.rotate(img, 270, order=1, preserve_range=True)\n",
        "        label = transform.rotate(label, 270, order=0, preserve_range=True)\n",
        "    elif rand_rotate < 0.50:\n",
        "        img = transform.rotate(img, 180, order=1, preserve_range=True)\n",
        "        label = transform.rotate(label, 180, order=0, preserve_range=True)\n",
        "    elif rand_rotate < 0.75:\n",
        "        img = transform.rotate(img, 90, order=1, preserve_range=True)\n",
        "        label = transform.rotate(label, 90, order=0, preserve_range=True)\n",
        "\n",
        "    img = img.astype(np.float32)\n",
        "    label = label.astype(np.int64)\n",
        "\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "pmVrwGdJucs1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils"
      ],
      "metadata": {
        "id": "TuyAP0UKuJBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "import random\n",
        "#import numpy as np\n",
        "#import imageio\n",
        "import argparse\n",
        "#import matplotlib.pyplot as plt\n",
        "#import torch\n",
        "\n",
        "\n",
        "def check_mkdir(dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.mkdir(dir_name)\n",
        "\n",
        "\n",
        "def str2bool(v):\n",
        "    \"\"\"\n",
        "    Function to transform strings into booleans.\n",
        "\n",
        "    v: string variable\n",
        "    \"\"\"\n",
        "    if isinstance(v, bool):\n",
        "        return v\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "\n",
        "def save_best_models(net, output_path, best_records, epoch, metric, num_saves=1,\n",
        "                     patch_acc_loss=None, patch_occur=None, patch_chosen_values=None):\n",
        "    if len(best_records) < num_saves:\n",
        "        best_records.append({'epoch': epoch, 'kappa': metric})\n",
        "\n",
        "        torch.save(net.state_dict(), os.path.join(output_path, 'model_' + str(epoch) + '.pth'))\n",
        "        if patch_acc_loss is not None and patch_occur is not None and patch_chosen_values is not None:\n",
        "            np.save(output_path + 'patch_acc_loss_step_' + str(epoch) + '.npy', patch_acc_loss)\n",
        "            np.save(output_path + 'patch_occur_step_' + str(epoch) + '.npy', patch_occur)\n",
        "            np.save(output_path + 'patch_chosen_values_step_' + str(epoch) + '.npy', patch_chosen_values)\n",
        "    else:\n",
        "        # find min saved acc\n",
        "        min_index = 0\n",
        "        for i, r in enumerate(best_records):\n",
        "            if best_records[min_index]['kappa'] > best_records[i]['kappa']:\n",
        "                min_index = i\n",
        "\n",
        "        # check if currect acc is greater than min saved acc\n",
        "        if metric > best_records[min_index]['kappa']:\n",
        "            # if it is, delete previous files\n",
        "            min_step = str(best_records[min_index]['epoch'])\n",
        "\n",
        "            os.remove(os.path.join(output_path, 'model_' + min_step + '.pth'))\n",
        "            # replace min value with current\n",
        "            best_records[min_index] = {'epoch': epoch, 'kappa': metric}\n",
        "            # save current model\n",
        "            torch.save(net.state_dict(), os.path.join(output_path, 'model_' + str(epoch) + '.pth'))\n",
        "\n",
        "            if patch_acc_loss is not None and patch_occur is not None and patch_chosen_values is not None:\n",
        "                os.remove(os.path.join(output_path, 'patch_acc_loss_step_' + min_step + '.npy'))\n",
        "                os.remove(os.path.join(output_path, 'patch_occur_step_' + min_step + '.npy'))\n",
        "                os.remove(os.path.join(output_path, 'patch_chosen_values_step_' + min_step + '.npy'))\n",
        "\n",
        "                np.save(output_path + 'patch_acc_loss_step_' + str(epoch) + '.npy', patch_acc_loss)\n",
        "                np.save(output_path + 'patch_occur_step_' + str(epoch) + '.npy', patch_occur)\n",
        "                np.save(output_path + 'patch_chosen_values_step_' + str(epoch) + '.npy', patch_chosen_values)\n",
        "\n",
        "    np.save(os.path.join(output_path, 'best_records.npy'), best_records)\n",
        "\n",
        "\n",
        "def define_multinomial_probs(values, dif_prob=2):\n",
        "    interval_size = values[-1] - values[0] + 1\n",
        "\n",
        "    general_prob = 1.0 / float(interval_size)\n",
        "    max_prob = general_prob * dif_prob  # for values\n",
        "\n",
        "    probs = np.full(interval_size, (1.0 - max_prob * len(values)) / float(interval_size - len(values)))\n",
        "    for i in range(len(values)):\n",
        "        probs[values[i] - values[0]] = max_prob\n",
        "\n",
        "    return probs\n",
        "\n",
        "\n",
        "def select_best_patch_size(distribution_type, values, patch_acc_loss, patch_occur, is_loss_or_acc='acc',\n",
        "                           patch_chosen_values=None, debug=False):\n",
        "        patch_occur[np.where(patch_occur == 0)] = 1\n",
        "        patch_mean = patch_acc_loss / patch_occur\n",
        "        # print is_loss_or_acc\n",
        "\n",
        "        if is_loss_or_acc == 'acc':\n",
        "            argmax_acc = np.argmax(patch_mean)\n",
        "            if distribution_type == 'multi_fixed':\n",
        "                cur_patch_val = int(values[argmax_acc])\n",
        "            elif distribution_type == 'uniform' or distribution_type == 'multinomial':\n",
        "                cur_patch_val = values[0] + argmax_acc\n",
        "\n",
        "            if patch_chosen_values is not None:\n",
        "                patch_chosen_values[int(argmax_acc)] += 1\n",
        "\n",
        "            if debug is True:\n",
        "                print('patch_acc_loss', patch_acc_loss)\n",
        "                print('patch_occur', patch_occur)\n",
        "                print('patch_mean', patch_mean)\n",
        "                print('argmax_acc', argmax_acc)\n",
        "\n",
        "                print('specific', argmax_acc, patch_acc_loss[argmax_acc], patch_occur[argmax_acc], patch_mean[argmax_acc])\n",
        "\n",
        "        elif is_loss_or_acc == 'loss':\n",
        "            arg_sort_out = np.argsort(patch_mean)\n",
        "\n",
        "            if debug is True:\n",
        "                print('patch_acc_loss', patch_acc_loss)\n",
        "                print('patch_occur', patch_occur)\n",
        "                print('patch_mean', patch_mean)\n",
        "                print('arg_sort_out', arg_sort_out)\n",
        "            if distribution_type == 'multi_fixed':\n",
        "                for i in range(len(values)):\n",
        "                    if patch_occur[arg_sort_out[i]] > 0:\n",
        "                        cur_patch_val = int(values[arg_sort_out[i]])  # -1*(i+1)\n",
        "                        if patch_chosen_values is not None:\n",
        "                            patch_chosen_values[arg_sort_out[i]] += 1\n",
        "                        if debug is True:\n",
        "                            print('specific', arg_sort_out[i], patch_acc_loss[arg_sort_out[i]], patch_occur[\n",
        "                                arg_sort_out[i]], patch_mean[arg_sort_out[i]])\n",
        "                        break\n",
        "            elif distribution_type == 'uniform' or distribution_type == 'multinomial':\n",
        "                for i in range(values[-1] - values[0] + 1):\n",
        "                    if patch_occur[arg_sort_out[i]] > 0:\n",
        "                        cur_patch_val = values[0] + arg_sort_out[i]\n",
        "                        if patch_chosen_values is not None:\n",
        "                            patch_chosen_values[arg_sort_out[i]] += 1\n",
        "                        if debug is True:\n",
        "                            print('specific', arg_sort_out[i], patch_acc_loss[arg_sort_out[i]], patch_occur[\n",
        "                                arg_sort_out[i]], patch_mean[arg_sort_out[i]])\n",
        "                        break\n",
        "\n",
        "        if debug is True:\n",
        "            print('Current patch size ', cur_patch_val)\n",
        "            if patch_chosen_values is not None:\n",
        "                print('Distr of chosen sizes ', patch_chosen_values)\n",
        "\n",
        "        return cur_patch_val\n",
        "\n",
        "\n",
        "def create_prediction_map(img_name, prob_img, channels=False):\n",
        "    if channels is True:\n",
        "        for i in range(prob_img.shape[-1]):\n",
        "            # imageio.imwrite(img_name + 'feat_' + str(i) + '.png', prob_img[:, :, i].astype(np.uint8))\n",
        "            plt.imsave(img_name + 'feat_' + str(i) + '.png', prob_img[:, :, i], cmap=plt.cm.jet)\n",
        "    else:\n",
        "        imageio.imwrite(img_name + '.png', prob_img.astype(np.uint8) * 255)\n",
        "        # img = Image.fromarray(prob_img.astype(np.uint8) * 255)\n",
        "        # img.save(img_name + \".tif\")\n",
        "\n",
        "\n",
        "def calc_accuracy_by_crop(true_crop, pred_crop, num_classes, track_conf_matrix, masks=None):\n",
        "    b, h, w = pred_crop.shape\n",
        "\n",
        "    acc = 0\n",
        "    local_conf_matrix = np.zeros((num_classes, num_classes), dtype=np.uint32)\n",
        "    # count = 0\n",
        "    for i in range(b):\n",
        "        for j in range(h):\n",
        "            for k in range(w):\n",
        "                if masks is None or (masks is not None and masks[i, j, k]):\n",
        "                    # count += 1\n",
        "                    if true_crop[i, j, k] == pred_crop[i, j, k]:\n",
        "                        acc = acc + 1\n",
        "                    if track_conf_matrix is not None:\n",
        "                        track_conf_matrix[true_crop[i, j, k]][pred_crop[i, j, k]] += 1\n",
        "                    local_conf_matrix[true_crop[i, j, k]][pred_crop[i, j, k]] += 1\n",
        "\n",
        "    # print count, b*h*w\n",
        "    return acc, local_conf_matrix\n",
        "\n",
        "\n",
        "def calc_accuracy_by_class(true_crop, pred_crop, num_classes, track_conf_matrix):\n",
        "    acc = 0\n",
        "    local_conf_matrix = np.zeros((num_classes, num_classes), dtype=np.uint32)\n",
        "    # count = 0\n",
        "    for i in range(len(true_crop)):\n",
        "        if true_crop[i] == pred_crop[i]:\n",
        "            acc = acc + 1\n",
        "        track_conf_matrix[true_crop[i]][pred_crop[i]] += 1\n",
        "        local_conf_matrix[true_crop[i]][pred_crop[i]] += 1\n",
        "\n",
        "    return acc, local_conf_matrix\n",
        "\n",
        "\n",
        "def create_cm(true, pred):\n",
        "    conf_matrix = np.zeros((len(np.unique(true)), len(np.unique(true))), dtype=np.uint32)\n",
        "    c, h, w = true.shape\n",
        "    for i in range(c):\n",
        "        for j in range(h):\n",
        "            for k in range(w):\n",
        "                conf_matrix[true[i, j, k]][pred[i, j, k]] += 1\n",
        "\n",
        "    return conf_matrix\n",
        "\n",
        "\n",
        "def kappa_with_cm(conf_matrix):\n",
        "    acc = 0\n",
        "    marginal = 0\n",
        "    total = float(np.sum(conf_matrix))\n",
        "    for i in range(len(conf_matrix)):\n",
        "        acc += conf_matrix[i][i]\n",
        "        marginal += np.sum(conf_matrix, 0)[i] * np.sum(conf_matrix, 1)[i]\n",
        "\n",
        "    kappa = (total * acc - marginal) / (total * total - marginal)\n",
        "    return kappa\n",
        "\n",
        "\n",
        "def f1_with_cm(conf_matrix):\n",
        "    precision = [0] * len(conf_matrix)\n",
        "    recall = [0] * len(conf_matrix)\n",
        "    f1 = [0] * len(conf_matrix)\n",
        "    for i in range(len(conf_matrix)):\n",
        "        precision[i] = conf_matrix[i][i] / float(np.sum(conf_matrix, 0)[i])\n",
        "        recall[i] = conf_matrix[i][i] / float(np.sum(conf_matrix, 1)[i])\n",
        "        f1[i] = 2 * ((precision[i]*recall[i])/(precision[i]+recall[i]))\n",
        "\n",
        "    return np.mean(f1)\n",
        "\n",
        "\n",
        "def jaccard_with_cm(conf_matrix):\n",
        "    den = float(np.sum(conf_matrix[:, 1]) + np.sum(conf_matrix[1]) - conf_matrix[1][1])\n",
        "    _sum_iou = conf_matrix[1][1] / den if den != 0 else 0\n",
        "\n",
        "    return _sum_iou\n"
      ],
      "metadata": {
        "id": "WkZscUy3uM__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "xYrHMo31Cn4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training_data and vali_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J_wDfE7fCuD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NGDataset(data.Dataset):\n",
        "  def __init__(self, img_dir, mask_dir, output_path):\n",
        "\n",
        "    #self.dataset_input_path = dataset_input_path\n",
        "    #self.images = images\n",
        "    self.img_dir = img_dir\n",
        "    self.mask_dir = mask_dir\n",
        "    self.images = os.listdir(img_dir)\n",
        "    self.masks = os.listdir(mask_dir)\n",
        "\n",
        "    self.output_path = output_path\n",
        "\n",
        "\n",
        "    print(\"debug1\")\n",
        "    # data and label\n",
        "    self.data, self.labels = self.load_images()\n",
        "    print(\"debug2\")\n",
        "    #print(self.data.ndim, self.data.shape, self.data[0].shape, np.min(self.data), np.max(self.data),\n",
        "    #      self.labels.shape, np.bincount(self.labels.astype(int).flatten()))\n",
        "\n",
        "    if self.data.ndim == 4:  # if all images have the same shape\n",
        "       self.num_channels = self.data.shape[-1]  # get the number of channels\n",
        "    else:\n",
        "       self.num_channels = self.data[0].shape[-1]  # get the number of channels\n",
        "\n",
        "    self.num_classes = 2  # binary - two classes\n",
        "    # negative classes will be converted into 2 so they can be ignored in the loss\n",
        "    self.labels[np.where(self.labels < 0)] = 2\n",
        "    \n",
        "    print('num_channels and labels', self.num_channels, self.num_classes, np.bincount(self.labels.flatten()))\n",
        "\n",
        "    #self.distrib, self.gen_classes = self.make_dataset()\n",
        "\n",
        "    self.mean, self.std = compute_image_mean(self.data)\n",
        "\n",
        "  print(\"debug3\")\n",
        "\n",
        "\n",
        "  def load_images(self):\n",
        "        images = []\n",
        "        masks = []\n",
        "        for img in self.images:\n",
        "            temp_image = imageio.imread(os.path.join(self.img_dir, img + '')).astype(np.float64)\n",
        "            temp_image[np.where(temp_image < -1.0e+38)] = 0 # remove extreme negative values (probably NO_DATA values)\n",
        "            \n",
        "            images.append(temp_image)\n",
        "\n",
        "        for msk in self.masks:\n",
        "            temp_mask = imageio.imread(os.path.join(self.mask_dir, msk + '')).astype(int)\n",
        "            temp_mask[np.where(temp_mask < -1.0e+38)] = 0\n",
        "\n",
        "            masks.append(temp_mask)\n",
        "\n",
        "        return np.asarray(images), np.asarray(masks)\n",
        "\n",
        "  \n",
        "  print(\"debug4\")\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \n",
        "    #Reading items from list.\n",
        "    img = self.data[index]\n",
        "    label = self.labels[index]\n",
        "\n",
        "    # Normalization.\n",
        "    normalize_images(img, self.mean, self.std) # check data_utils.py\n",
        "    \n",
        "    # Data augmentation\n",
        "    img, label = data_augmentation(img, label)\n",
        "     \n",
        "    img = np.transpose(img, (2, 0, 1))\n",
        "\n",
        "    # Turning to tensors.\n",
        "    img = torch.from_numpy(img.copy())\n",
        "    label = torch.from_numpy(label.copy())\n",
        "\n",
        "    # Returning to iterator.\n",
        "    return img.float(), label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  print(\"debug5\")\n"
      ],
      "metadata": {
        "id": "Q7UNPeWWDVF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1654ec2-5043-4422-b543-41eab2c13cd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debug3\n",
            "debug4\n",
            "debug5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading train set\n",
        "\n",
        "img_path = '/content/drive/MyDrive/training_data/image'\n",
        "mask_path = '/content/drive/MyDrive/training_data/mask'\n",
        "output_path = '/content/drive/MyDrive/outputs/'\n",
        "\n",
        "#images = os.listdir(input_path)\n",
        "\n",
        "train_set = NGDataset(img_path, mask_path, output_path)"
      ],
      "metadata": {
        "id": "x-R2MNNomgIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372c1ead-9bc9-4f62-acab-ccc6dfb0e9db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debug1\n",
            "debug2\n",
            "num_channels and labels 23 2 [29044396 17830604]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "img, msk = train_set[0][0], train_set[0][1] \n",
        "print(img.shape)\n",
        "print(msk.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55JTir-ypTJE",
        "outputId": "afee01ff-a510-4aee-d0bf-8917cbbc4c7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([23, 250, 250])\n",
            "torch.Size([250, 250])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading vali set\n",
        "\n",
        "vali_img_path = '/content/drive/MyDrive/vali_data/images'\n",
        "vali_mask_path = '/content/drive/MyDrive/vali_data/masks'\n",
        "output_path = '/content/drive/MyDrive/outputs/'\n",
        "\n",
        "#images = os.listdir(input_path)\n",
        "\n",
        "validation_set = NGDataset(vali_img_path, vali_mask_path, output_path)\n",
        "\n",
        "# sanity check\n",
        "i, m = validation_set[0][0], validation_set[0][1] \n",
        "print(i.shape)\n",
        "print(m.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgz4UeSTouln",
        "outputId": "7953536f-f19d-4cbb-dde4-0c463d8bee15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debug1\n",
            "debug2\n",
            "num_channels and labels 23 2 [6525140 9099860]\n",
            "torch.Size([23, 250, 250])\n",
            "torch.Size([250, 250])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training"
      ],
      "metadata": {
        "id": "6buxL7lciTgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import torch.optim as optim\n",
        "\n",
        "from albumentations.pytorch import ToTensorsV2\n",
        "from tqdm import tqdm \n",
        "\n",
        "#from utils import (\n",
        "#    load_checkpoint,\n",
        "#    save_checkpoint,\n",
        "#    get_loaders,\n",
        "#    check_accuracy\n",
        "#    save_predictions_as_imgs\n",
        "#)\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    # Setting network for training mode.\n",
        "    model.train()\n",
        "\n",
        "    # Average Meter for batch loss.\n",
        "    train_loss = list()\n",
        "\n",
        "    # Iterating over batches.\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, labels = data[0], data[1]\n",
        "\n",
        "        # if the current batch does not have samples from all classes\n",
        "        # print('out i', i, len(np.unique(labels.flatten())))\n",
        "        # if len(np.unique(labels.flatten())) < 10:\n",
        "        #     print('in i', i, len(np.unique(labels.flatten())))\n",
        "        #     continue\n",
        "\n",
        "        # Casting tensors to cuda.\n",
        "        inps = Variable(inps).cuda()\n",
        "        labs = Variable(labels).cuda()\n",
        "\n",
        "        # Clears the gradients of optimizer.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forwarding.\n",
        "        outs = model(inps)\n",
        "\n",
        "        # Computing loss.\n",
        "        loss = criterion(outs, labs)\n",
        "\n",
        "        if math.isnan(loss):\n",
        "            print('-------------------------NaN-----------------------------------------------')\n",
        "            print(inps.shape, labels.shape, outs.shape, np.bincount(labels.flatten()))\n",
        "            print(np.min(inps.cpu().data.numpy()), np.max(inps.cpu().data.numpy()),\n",
        "                  np.isnan(inps.cpu().data.numpy()).any())\n",
        "            print(np.min(labels.cpu().data.numpy()), np.max(labels.cpu().data.numpy()),\n",
        "                  np.isnan(labels.cpu().data.numpy()).any())\n",
        "            print(np.min(outs.cpu().data.numpy()), np.max(outs.cpu().data.numpy()),\n",
        "                  np.isnan(outs.cpu().data.numpy()).any())\n",
        "            print('-------------------------NaN-----------------------------------------------')\n",
        "            raise AssertionError\n",
        "\n",
        "        # Computing backpropagation.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Updating loss meter.\n",
        "        train_loss.append(loss.data.item())\n",
        "\n",
        "        # Printing.\n",
        "        if (i + 1) % DISPLAY_STEP == 0:\n",
        "            soft_outs = F.softmax(outs, dim=1)\n",
        "            # Obtaining predictions.\n",
        "            prds = soft_outs.cpu().data.numpy().argmax(axis=1).flatten()\n",
        "\n",
        "            labels = labels.cpu().data.numpy().flatten()\n",
        "\n",
        "            # filtering out pixels\n",
        "            coord = np.where(labels != train_loader.dataset.num_classes)\n",
        "            labels = labels[coord]\n",
        "            prds = prds[coord]\n",
        "\n",
        "            acc = accuracy_score(labels, prds)\n",
        "            conf_m = confusion_matrix(labels, prds, labels=[0, 1])\n",
        "            f1_s = f1_score(labels, prds, average='weighted')\n",
        "\n",
        "            _sum = 0.0\n",
        "            for k in range(len(conf_m)):\n",
        "                _sum += (conf_m[k][k] / float(np.sum(conf_m[k])) if np.sum(conf_m[k]) != 0 else 0)\n",
        "\n",
        "            print(\"Training -- Epoch \" + str(epoch) + \" -- Iter \" + str(i + 1) + \"/\" + str(len(train_loader)) +\n",
        "                  \" -- Time \" + str(datetime.datetime.now().time()) +\n",
        "                  \" -- Training Minibatch: Loss= \" + \"{:.6f}\".format(train_loss[-1]) +\n",
        "                  \" Overall Accuracy= \" + \"{:.4f}\".format(acc) +\n",
        "                  \" Normalized Accuracy= \" + \"{:.4f}\".format(_sum / float(train_loader.dataset.num_classes)) +\n",
        "                  \" F1 Score= \" + \"{:.4f}\".format(f1_s) +\n",
        "                  \" Confusion Matrix= \" + np.array_str(conf_m).replace(\"\\n\", \"\")\n",
        "                  )\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    return sum(train_loss) / len(train_loss), _sum / float(train_loader.dataset.num_classes)\n",
        "\n",
        "# CREATE OWN MAIN\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='main')\n",
        "    # general options\n",
        "    parser.add_argument('--operation', type=str, required=True, help='Operation [Options: Train | Test]')\n",
        "    parser.add_argument('--output_path', type=str, required=True,\n",
        "                        help='Path to to save outcomes (such as images and trained models) of the algorithm.')\n",
        "\n",
        "    # dataset options\n",
        "    parser.add_argument('--dataset_path', type=str, required=True, help='Dataset path.')\n",
        "    parser.add_argument('--training_images', type=str, nargs=\"+\", required=True, help='Training image names.') # WHAT DO I DO IF I ONLY HAVE FOLDER?\n",
        "    parser.add_argument('--testing_images', type=str, nargs=\"+\", required=True, help='Testing image names.')\n",
        "    parser.add_argument('--crop_size', type=int, required=True, help='Crop size.')\n",
        "    parser.add_argument('--stride_crop', type=int, required=True, help='Stride size')\n",
        "\n",
        "    # model options\n",
        "    parser.add_argument('--model_name', type=str, required=True,\n",
        "                        choices=['deeplab', 'fcnwideresnet'], help='Model to evaluate')\n",
        "    parser.add_argument('--model_path', type=str, default=None, help='Model path.')\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.01, help='Learning rate')\n",
        "    parser.add_argument('--weight_decay', type=float, default=0.005, help='Weight decay')\n",
        "    parser.add_argument('--batch_size', type=int, default=128, help='Batch size')\n",
        "    parser.add_argument('--epoch_num', type=int, default=500, help='Number of epochs')\n",
        "\n",
        "    # handling imbalanced data\n",
        "    parser.add_argument('--loss_weight', type=float, nargs='+', default=[1.0, 1.0], help='Weight Loss.')\n",
        "    parser.add_argument('--weight_sampler', type=str2bool, default=False, help='Use weight sampler for loader?')\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "\n",
        "    # Making sure output directory is created.\n",
        "    pathlib.Path(args.output_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # writer for the tensorboard\n",
        "    writer = SummaryWriter(os.path.join(args.output_path, 'logs'))\n",
        "\n",
        "    if args.operation == 'Train':\n",
        "        print('---- training data ----')\n",
        "        train_set = DataLoader('Train', args.dataset_path, args.training_images, args.crop_size, args.stride_crop,\n",
        "                               args.output_path)\n",
        "        print('---- testing data ----')\n",
        "        test_set = DataLoader('Test', args.dataset_path, args.testing_images, args.crop_size, args.stride_crop,\n",
        "                              args.output_path)\n",
        "\n",
        "        if args.weight_sampler is False:\n",
        "            train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size,\n",
        "                                                       shuffle=True, num_workers=NUM_WORKERS, drop_last=False)\n",
        "        else:\n",
        "            class_loader_weights = 1. / np.bincount(train_set.gen_classes)\n",
        "            samples_weights = class_loader_weights[train_set.gen_classes]\n",
        "            sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weights, len(samples_weights),\n",
        "                                                                     replacement=True)\n",
        "            train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size,\n",
        "                                                       num_workers=NUM_WORKERS, drop_last=False, sampler=sampler)\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size,\n",
        "                                                  shuffle=False, num_workers=NUM_WORKERS, drop_last=False)\n",
        "\n",
        "        # Setting network architecture.\n",
        "        model = model_factory(args.model_name, train_set.num_channels, train_set.num_classes).cuda()\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(args.loss_weight),\n",
        "                                        ignore_index=train_set.num_classes).cuda()\n",
        "\n",
        "        # Setting optimizer.\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay,\n",
        "                               betas=(0.9, 0.99))\n",
        "        # optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay, momentum=0.9)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
        "\n",
        "        curr_epoch = 1\n",
        "        best_records = []\n",
        "        if args.model_path is not None:\n",
        "            print('Loading model ' + args.model_path)\n",
        "            best_records = np.load(os.path.join(args.output_path, 'best_records.npy'), allow_pickle=True)\n",
        "            model.load_state_dict(torch.load(args.model_path))\n",
        "            # optimizer.load_state_dict(torch.load(args.model_path.replace(\"model\", \"opt\")))\n",
        "            curr_epoch += int(os.path.basename(args.model_path)[:-4].split('_')[-1])\n",
        "            for i in range(curr_epoch):\n",
        "                scheduler.step()\n",
        "        model.cuda()\n",
        "\n",
        "        # Iterating over epochs.\n",
        "        print('---- training ----')\n",
        "        for epoch in range(curr_epoch, args.epoch_num + 1):\n",
        "            # Training function.\n",
        "            t_loss, t_nacc = train(train_loader, model, criterion, optimizer, epoch)\n",
        "            writer.add_scalar('Train/loss', t_loss, epoch)\n",
        "            writer.add_scalar('Train/acc', t_nacc, epoch)\n",
        "            if epoch % VAL_INTERVAL == 0:\n",
        "                # Computing test.\n",
        "                acc, nacc, f1_s, kappa, track_cm = test_full_map(test_loader, model, epoch, args.output_path)\n",
        "                writer.add_scalar('Test/acc', nacc, epoch)\n",
        "                save_best_models(model, args.output_path, best_records, epoch, kappa)\n",
        "                # patch_acc_loss=None, patch_occur=None, patch_chosen_values=None\n",
        "            scheduler.step()\n",
        "    elif args.operation == 'Test':\n",
        "        print('---- testing data ----')\n",
        "        test_set = DataLoader('Test', args.dataset_path, args.training_images, args.crop_size, args.stride_crop,\n",
        "                              args.output_path)\n",
        "        test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size,\n",
        "                                                  shuffle=False, num_workers=NUM_WORKERS, drop_last=False)\n",
        "\n",
        "        # Setting network architecture.\n",
        "        model = model_factory(args.model_name, test_set.num_channels, test_set.num_classes).cuda()\n",
        "\n",
        "        best_records = np.load(os.path.join(args.output_path, 'best_records.npy'), allow_pickle=True)\n",
        "        index = 0\n",
        "        for i in range(len(best_records)):\n",
        "            if best_records[index]['kappa'] < best_records[i]['kappa']:\n",
        "                index = i\n",
        "        epoch = int(best_records[index]['epoch'])\n",
        "        print(\"loading model_\" + str(epoch) + '.pth')\n",
        "        model.load_state_dict(torch.load(os.path.join(args.output_path, 'model_' + str(epoch) + '.pth')))\n",
        "        model.cuda()\n",
        "\n",
        "        test_full_map(test_loader, model, epoch, args.output_path)\n",
        "    else:\n",
        "        raise NotImplementedError(\"Process \" + args.operation + \"not found!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Z8SO1kqAiQVy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}